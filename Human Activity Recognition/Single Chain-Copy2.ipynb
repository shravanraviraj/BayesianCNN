{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "studied-accountability",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import copy\n",
    "import multiprocessing\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import operator\n",
    "import math\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import pickle\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "renewable-matthew",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a single file as a numpy array\n",
    "def load_file(filepath):\n",
    "\tdataframe = read_csv(filepath, header=None, delim_whitespace=True)\n",
    "\treturn dataframe.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "great-queen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a list of files and return as a 3d numpy array\n",
    "def load_group(filenames, prefix=''):\n",
    "\tloaded = list()\n",
    "\tfor name in filenames:\n",
    "\t\tdata = load_file(prefix + name)\n",
    "\t\tloaded.append(data)\n",
    "\t# stack group so that features are the 3rd dimension\n",
    "\tloaded = dstack(loaded)\n",
    "\treturn loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sought-cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_group(group, prefix=''):\n",
    "\tfilepath = prefix + group + '/Inertial Signals/'\n",
    "\t# load all 9 files as a single array\n",
    "\tfilenames = list()\n",
    "\t# total acceleration\n",
    "\tfilenames += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n",
    "\t# body acceleration\n",
    "\tfilenames += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n",
    "\t# body gyroscope\n",
    "\tfilenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n",
    "\t# load input data\n",
    "\tX = load_group(filenames, filepath)\n",
    "\t# load class output\n",
    "\ty = load_file(prefix + group + '/y_'+group+'.txt')\n",
    "\treturn X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "thick-speaking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset, returns train and test X and y elements\n",
    "def load_dataset(prefix=''):\n",
    "    # load all train\n",
    "    trainX, trainy = load_dataset_group('train', prefix + 'UCI HAR Dataset/UCI HAR Dataset/')\n",
    "    print(trainX.shape, trainy.shape)\n",
    "    # load all test\n",
    "    testX, testy = load_dataset_group('test', prefix + 'UCI HAR Dataset/UCI HAR Dataset/')\n",
    "    print(testX.shape, testy.shape)\n",
    "    # zero-offset class values\n",
    "    trainy = trainy - 1\n",
    "    testy = testy - 1\n",
    "    ty = trainy\n",
    "    tty=testy\n",
    "    # one hot encode y\n",
    "    #trainy = to_categorical(trainy)\n",
    "    #testy = to_categorical(testy)\n",
    "    trainy.flatten()\n",
    "    print(trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
    "    return trainX, trainy, testX, testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abroad-miracle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 128, 9) (7352, 1)\n",
      "(2947, 128, 9) (2947, 1)\n",
      "(7352, 128, 9) (7352, 1) (2947, 128, 9) (2947, 1)\n"
     ]
    }
   ],
   "source": [
    "trainX, trainy, testX, testy = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "promotional-associate",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIX THIS FUNCTION\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "# * parameter to keep track of already run samples\n",
    "samples_run = 0\n",
    "load = False\n",
    "# Hyper-Parameters\n",
    "\n",
    "input_size = 320  # Junk\n",
    "hidden_size = 50  # Junk\n",
    "num_layers = 2  # Junk\n",
    "num_classes = 6\n",
    "batch_size = 16\n",
    "batch_Size = batch_size\n",
    "step_size = 10\n",
    "verbose, epochs, batch_size = 0, 10, 16#32\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "def data_load(data='train'):\n",
    "    if data == 'test':\n",
    "        #transform to torch tensor\n",
    "        tensor_x = torch.Tensor(testX)                     #(np.expand_dims(testX[:, :, :], axis=1))\n",
    "        tensor_y = torch.Tensor(testy)\n",
    "        a = TensorDataset(tensor_x,tensor_y)       #TensorDataset(tensor_x, tensor_y)\n",
    "\n",
    "    else:\n",
    "        # transform to torch tensor\n",
    "        tensor_x = torch.Tensor(trainX)\n",
    "        tensor_y = torch.Tensor(trainy)\n",
    "        a =  TensorDataset(tensor_x, tensor_y)          #TensorDataset(tensor_x, tensor_y)\n",
    "\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        a, batch_size=batch_Size, shuffle=True)\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "continuous-negotiation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beginning sampling\n",
      "0 tensor(0.5190) tensor(0.7317) 327.97878128400436 319.2399049881235 rejected\n",
      "1 tensor(0.7246) tensor(0.8908) 329.70620239390644 326.46759416355616 rejected\n",
      "2 tensor(0.5363) tensor(0.9129) 326.83623503808485 320.93654563963355 rejected\n",
      "3 tensor(0.7124) tensor(1.0886) 324.1430903155604 313.7088564642009 rejected\n",
      "4 tensor(0.3657) tensor(1.1350) 337.6904243743199 339.29419748897186 rejected\n",
      "5 tensor(0.4515) tensor(0.7160) 333.24265505984766 334.407872412623 rejected\n",
      "6 tensor(0.6108) tensor(4.6167) 340.60119695321004 327.99457074991517 rejected\n",
      "7 tensor(0.6207) tensor(1.6402) 330.9031556039173 326.73905666779774 rejected\n",
      "8 tensor(1.8098) tensor(3.1662) 318.9200217627856 316.4913471326773 rejected\n",
      "9 tensor(3.2087) tensor(4.6985) 309.60282916213276 306.82049541907026 rejected\n",
      "10 tensor(0.5949) tensor(1.7296) 327.43471164309034 326.12826603325414 rejected\n",
      "11 tensor(0.5256) tensor(1.2596) 339.689880304679 321.1740753308449 rejected\n",
      "12 tensor(3.0978) tensor(3.2761) 308.9771490750816 306.92229385816086 rejected\n",
      "13 tensor(2.9563) tensor(3.4437) 324.61915125136017 317.5771971496437 rejected\n",
      "14 tensor(0.5922) tensor(1.6420) 338.9417845484222 330.2341364099084 rejected\n",
      "15 tensor(0.6901) tensor(2.3197) 330.3318824809576 318.5273159144893 rejected\n",
      "16 tensor(1.2205) tensor(4.2352) 330.05984766050057 315.3036986766203 rejected\n",
      "17 tensor(1.3113) tensor(3.5143) 324.34711643090316 309.8744485917883 rejected\n",
      "18 tensor(1.7095) tensor(2.9463) 311.6838955386289 299.0838140481846 rejected\n",
      "19 tensor(1.6676) tensor(7.0560) 276.2105549510337 279.57244655581945 rejected\n",
      "20 tensor(1.7823) tensor(1.8839) 306.21599564744287 291.31319986426877 accepted\n",
      "21 tensor(1.7824) tensor(1.8205) 306.33841131664855 291.51679674244997 rejected\n",
      "22 tensor(1.7862) tensor(1.8112) 306.0119695321001 291.38106549032915 accepted\n",
      "23 tensor(1.7882) tensor(1.8106) 306.3520130576714 291.51679674244997 rejected\n",
      "24 tensor(1.7716) tensor(2.0287) 306.9232861806311 290.97387173396675 accepted\n",
      "25 tensor(1.7713) tensor(2.0079) 298.68063112078346 288.83610451306413 rejected\n",
      "26 tensor(1.7747) tensor(2.1579) 306.8144722524483 291.85612487275193 accepted\n",
      "27 tensor(1.7842) tensor(1.7903) 298.5854189336235 288.3949779436715 rejected\n",
      "28 tensor(1.7853) tensor(1.7906) 279.651795429815 266.5761791652528 accepted\n",
      "29 tensor(1.7878) tensor(1.7933) 279.76060935799785 266.5761791652528 rejected\n",
      "30 tensor(1.7977) tensor(1.7929) 305.9847660500544 291.55072955548013 rejected\n",
      "31 tensor(1.7845) tensor(1.7900) 305.9847660500544 291.55072955548013 accepted\n",
      "32 tensor(1.7862) tensor(1.7909) 306.0935799782372 291.10960298608757 rejected\n",
      "33 tensor(1.7842) tensor(1.7911) 305.9847660500544 291.55072955548013 accepted\n",
      "34 tensor(1.7851) tensor(1.7922) 306.0935799782372 291.55072955548013 rejected\n",
      "35 tensor(1.7853) tensor(1.7917) 305.9847660500544 291.55072955548013 rejected\n",
      "36 tensor(1.8368) tensor(1.8232) 305.9575625680087 291.21140142517817 rejected\n",
      "37 tensor(1.7911) tensor(1.7909) 298.9118607181719 288.83610451306413 accepted\n",
      "38 tensor(1.7854) tensor(1.7923) 305.76713819368877 291.10960298608757 accepted\n",
      "39 tensor(1.7861) tensor(1.7927) 305.9847660500544 291.55072955548013 rejected\n",
      "40 tensor(1.7858) tensor(1.8124) 305.97116430903156 291.55072955548013 rejected\n",
      "41 tensor(1.7952) tensor(1.8131) 306.0799782372144 291.0417373600271 rejected\n",
      "42 tensor(1.7864) tensor(1.7919) 306.0527747551687 291.17746861214795 rejected\n",
      "43 tensor(1.7846) tensor(1.7903) 298.7894450489663 288.83610451306413 accepted\n",
      "44 tensor(1.7843) tensor(1.7875) 306.21599564744287 291.65252799457073 rejected\n",
      "45 tensor(1.7822) tensor(2.5535) 306.1207834602829 291.72039362063117 accepted\n",
      "46 tensor(1.9082) tensor(1.7930) 306.16158868335145 291.44893111638953 rejected\n",
      "47 tensor(1.7856) tensor(2.7959) 306.3792165397171 291.51679674244997 rejected\n",
      "48 tensor(1.7974) tensor(2.6484) 306.5152339499456 291.75432643366133 accepted\n",
      "49 tensor(1.7809) tensor(5.9443) 299.0070729053319 288.3949779436715 accepted\n",
      "50 tensor(1.9359) tensor(1.9837) 306.7056583242655 291.72039362063117 rejected\n",
      "51 tensor(1.9461) tensor(3.8461) 306.29760609358 291.99185612487275 rejected\n",
      "52 tensor(1.8864) tensor(2.8488) 298.77584330794343 288.3949779436715 rejected\n",
      "53 tensor(1.7828) tensor(2.7147) 298.9118607181719 287.95385137427894 rejected\n",
      "54 tensor(1.7831) tensor(1.7901) 306.1479869423286 291.17746861214795 accepted\n",
      "55 tensor(1.7973) tensor(1.7906) 306.1751904243743 291.55072955548013 rejected\n",
      "56 tensor(1.7842) tensor(1.7906) 306.20239390642 291.61859518154057 accepted\n",
      "57 tensor(1.7859) tensor(1.7924) 266.59412404787815 268.8496776382762 rejected\n",
      "58 tensor(1.7865) tensor(1.7945) 305.8759521218716 291.55072955548013 rejected\n",
      "59 tensor(1.7869) tensor(1.7945) 305.9031556039173 291.17746861214795 rejected\n",
      "60 tensor(1.7843) tensor(2.4257) 306.28400435255713 291.10960298608757 accepted\n",
      "61 tensor(1.7851) tensor(1.7924) 306.1479869423286 291.17746861214795 rejected\n",
      "62 tensor(1.7827) tensor(1.7886) 298.6942328618063 288.3949779436715 accepted\n",
      "63 tensor(1.7855) tensor(1.9621) 298.7622415669206 288.83610451306413 rejected\n",
      "64 tensor(1.7839) tensor(1.7903) 306.4064200217628 291.85612487275193 accepted\n",
      "65 tensor(1.7926) tensor(1.9642) 306.16158868335145 291.41499830335937 accepted\n",
      "66 tensor(6.4040) tensor(5.3708) 305.37268770402613 292.67051238547674 rejected\n",
      "67 tensor(1.7851) tensor(1.8119) 306.21599564744287 291.55072955548013 accepted\n",
      "68 tensor(1.8067) tensor(1.7894) 306.0935799782372 291.55072955548013 rejected\n",
      "69 tensor(1.7847) tensor(1.7918) 305.9847660500544 291.55072955548013 accepted\n",
      "70 tensor(1.8440) tensor(1.7921) 305.9575625680087 291.1435357991177 rejected\n",
      "71 tensor(1.8192) tensor(1.7905) 305.9575625680087 291.00780454699697 accepted\n",
      "72 tensor(1.9089) tensor(1.7894) 305.99836779107727 291.10960298608757 rejected\n",
      "73 tensor(1.7855) tensor(1.7945) 306.20239390642 291.10960298608757 accepted\n",
      "74 tensor(1.7851) tensor(1.7913) 305.9847660500544 291.10960298608757 accepted\n",
      "75 tensor(1.7847) tensor(1.7903) 305.88955386289445 291.55072955548013 accepted\n",
      "76 tensor(1.7865) tensor(1.7933) 306.0935799782372 291.10960298608757 rejected\n",
      "77 tensor(1.7861) tensor(1.7941) 306.0935799782372 291.10960298608757 accepted\n",
      "78 tensor(1.7848) tensor(1.7919) 306.1207834602829 291.55072955548013 accepted\n",
      "79 tensor(1.7862) tensor(1.7904) 305.67192600652885 291.55072955548013 rejected\n",
      "80 tensor(1.7853) tensor(1.7909) 305.9847660500544 291.55072955548013 accepted\n",
      "81 tensor(1.7869) tensor(1.7925) 306.0935799782372 291.55072955548013 rejected\n",
      "82 tensor(1.7845) tensor(1.7905) 298.6942328618063 288.83610451306413 accepted\n",
      "83 tensor(1.7846) tensor(1.7899) 306.20239390642 291.10960298608757 rejected\n",
      "84 tensor(1.7851) tensor(1.7916) 306.0935799782372 291.55072955548013 rejected\n",
      "85 tensor(1.7859) tensor(1.7903) 298.9118607181719 287.95385137427894 accepted\n",
      "86 tensor(1.7858) tensor(1.7904) 298.6942328618063 288.83610451306413 rejected\n",
      "87 tensor(1.7855) tensor(1.7936) 305.9847660500544 290.66847641669494 accepted\n",
      "88 tensor(1.7860) tensor(1.7904) 298.9118607181719 288.3949779436715 rejected\n",
      "89 tensor(1.7853) tensor(1.7907) 298.9118607181719 288.3949779436715 rejected\n",
      "90 tensor(1.7844) tensor(1.7908) 305.9847660500544 291.55072955548013 accepted\n",
      "91 tensor(1.7847) tensor(1.7910) 279.76060935799785 266.5761791652528 accepted\n",
      "92 tensor(1.7869) tensor(1.7920) 298.9118607181719 288.83610451306413 rejected\n",
      "93 tensor(1.7846) tensor(1.7891) 305.930359085963 291.10960298608757 accepted\n",
      "94 tensor(1.7846) tensor(1.7905) 306.0935799782372 291.55072955548013 rejected\n",
      "95 tensor(1.7860) tensor(1.7909) 305.8759521218716 291.55072955548013 accepted\n",
      "96 tensor(1.7875) tensor(1.7918) 306.18879216539716 291.55072955548013 rejected\n",
      "97 tensor(1.7896) tensor(1.7932) 266.7029379760609 268.8496776382762 rejected\n",
      "98 tensor(2.2415) tensor(2.8382) 305.7943416757345 291.51679674244997 rejected\n",
      "99 tensor(2.3036) tensor(1.8411) 306.18879216539716 291.58466236851035 rejected\n",
      "\n",
      "\n",
      "Total time taken for Sampling :  776.6137452125549\n",
      "35.0 % was Accepted\n",
      "52.0 % was Langevin\n",
      "\n",
      "Shape of acc_test :  (75,)\n",
      "\n",
      "Shape of sva :  (75,)\n",
      "\n",
      "Shape of wa :  (100,)\n",
      "\n",
      "Shape of wa1 :  (100,)\n",
      "\n",
      "Shape of wa2 :  (100,)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Mean of RMSE Train\n",
      "1.785389765103658\n",
      "\n",
      "\n",
      "Mean of Accuracy Train\n",
      "302.8752266956837\n",
      "\n",
      "\n",
      "Mean of RMSE Test\n",
      "2.1448926798502606\n",
      "\n",
      "\n",
      "Mean of Accuracy Test\n",
      "289.1618595181541\n",
      "sucessfully sampled\n"
     ]
    },
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: 'HAR_SINGLECHAIN2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f5e03f815d87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-f5e03f815d87>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m     \u001b[0mproblemfolder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'HAR_SINGLECHAIN2'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproblemfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'HAR_SINGLECHAIN2'"
     ]
    }
   ],
   "source": [
    "n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "\n",
    "mid_feature_size = 64\n",
    "mid_mlp = 100\n",
    "time_kernel_size = 3\n",
    "dropout = 0.5\n",
    "pool_size = 2\n",
    "out_maxpool = 62\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, topo, lrate, batch_size, cnn_net='CNN'):\n",
    "        super(Model, self).__init__()\n",
    "        if cnn_net == 'CNN':\n",
    "            self.conv1 = nn.Conv1d(in_channels = 128, out_channels = 64, kernel_size = 3, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
    "            self.conv2 = nn.Conv1d(64, 64,3)\n",
    "            self.dout = nn.Dropout(0.5)\n",
    "            self.pool = nn.MaxPool1d(2)\n",
    "            self.fc1 = nn.Linear(128,100)\n",
    "            self.fc2 = nn.Linear(100,54)\n",
    "            self.fc3 = nn.Linear(54,6)#n_outputs) #n_outputs = 6\n",
    "            \n",
    "            #self.conv1 = nn.Conv1d(in_channels = 128, out_channels = 64, kernel_size = 3, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
    "            #self.conv2 = nn.Conv1d(64, 64,3)\n",
    "            #self.dout = nn.Dropout(0.5)\n",
    "            #self.pool = nn.MaxPool1d(2)\n",
    "            #self.fc1 = nn.Linear(out_maxpool * mid_feature_size,100)\n",
    "            #self.fc2 = nn.Linear(100,n_outputs) #n_outputs = 6\n",
    "            \n",
    "        \n",
    "            self.batch_size = batch_size\n",
    "            self.sigmoid = nn.Sigmoid()\n",
    "            self.topo = topo\n",
    "            self.los = 0\n",
    "            # self.softmax = nn.Softmax(dim=1)\n",
    "            self.criterion = torch.torch.nn.CrossEntropyLoss()#nn.NLLLoss()\n",
    "            self.optimizer = torch.optim.Adam(self.parameters(), lr=lrate)\n",
    "            self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "   # def sigmoid(self, z):\n",
    "    #    return 1 / (1 + torch.exp(-z))\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = F.relu(self.conv1(x))\n",
    "        # x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.dout(x)\n",
    "        x = self.pool(x)\n",
    "        #x = x.reshape(x.shape[0], -1)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        #x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "    def evaluate_proposal(self, data, w=None):\n",
    "        self.los = 0\n",
    "        if w is not None:\n",
    "            self.loadparameters(w)\n",
    "        y_pred = torch.zeros((len(data), self.batch_size))\n",
    "        prob = torch.zeros((len(data), self.batch_size, self.topo[2]))\n",
    "        for i, sample in enumerate(data, 0):\n",
    "            inputs, labels = sample\n",
    "            labels = labels.view(labels.size(0)).type(torch.LongTensor)\n",
    "            a = copy.deepcopy(self.forward(inputs).detach())\n",
    "            _, predicted = torch.max(a.data, 1)\n",
    "            # y_pred[i] = torch.argmax(copy.deepcopy(a),dim=1)\n",
    "            if(labels.size(0)==16):\n",
    "                y_pred[i] = predicted\n",
    "            # print(a)\n",
    "            # print(a.shape)\n",
    "            # f()\n",
    "                b = copy.deepcopy(a)\n",
    "                prob[i] = self.softmax(b)\n",
    "            # prob[i] = self.softmax(a)\n",
    "            # print(predicted.shape)\n",
    "            # print(labels.shape)\n",
    "            \n",
    "                loss = self.criterion(a, labels)\n",
    "            self.los += loss\n",
    "        return y_pred, prob\n",
    "\n",
    "    def langevin_gradient(self, x, w=None):\n",
    "        if w is not None:\n",
    "            self.loadparameters(w)\n",
    "        # only one epoch\n",
    "        self.los = 0\n",
    "        # print(self.state_dict()['fc.weight'][0])\n",
    "        for i, sample in enumerate(x, 0):\n",
    "            inputs, labels = sample\n",
    "            outputs = self.forward(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            if(labels.size(0)==16):\n",
    "                loss = self.criterion(outputs, labels.view(labels.size(0)).type(torch.LongTensor))\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "            # if (i % 50 == 0):\n",
    "            # print(loss.item(), ' is loss', i)\n",
    "            self.los += copy.deepcopy(loss.item())\n",
    "        # print(lo,' is loss')\n",
    "        return copy.deepcopy(self.state_dict())\n",
    "\n",
    "    def getparameters(self, w=None):\n",
    "        l = np.array([1, 2])\n",
    "        dic = {}\n",
    "        if w is None:\n",
    "            dic = self.state_dict()\n",
    "        else:\n",
    "            dic = copy.deepcopy(w)\n",
    "        for name in sorted(dic.keys()):\n",
    "            l = np.concatenate((l, np.array(copy.deepcopy(dic[name])).reshape(-1)), axis=None)\n",
    "        l = l[2:]\n",
    "        return l\n",
    "\n",
    "    def dictfromlist(self, param):\n",
    "        dic = {}\n",
    "        i = 0\n",
    "        for name in sorted(self.state_dict().keys()):\n",
    "            dic[name] = torch.FloatTensor(param[i:i + (self.state_dict()[name]).view(-1).shape[0]]).view(\n",
    "                self.state_dict()[name].shape)\n",
    "            i += (self.state_dict()[name]).view(-1).shape[0]\n",
    "        # self.loadparameters(dic)\n",
    "        return dic\n",
    "\n",
    "    def loadparameters(self, param):\n",
    "        self.load_state_dict(param)\n",
    "\n",
    "    def addnoiseandcopy(self, mea, std_dev):\n",
    "        dic = {}\n",
    "        w = self.state_dict()\n",
    "        for name in (w.keys()):\n",
    "            dic[name] = copy.deepcopy(w[name]) + torch.zeros(w[name].size()).normal_(mean=mea, std=std_dev)\n",
    "        self.loadparameters(dic)\n",
    "        return dic\n",
    "\n",
    "\n",
    "class MCMC:\n",
    "    def __init__(self, samples, topology, use_langevin_gradients, lr, batch_size):\n",
    "        self.samples = samples\n",
    "        self.topology = topology\n",
    "        self.rnn = Model(topology, lr, batch_size)\n",
    "        self.traindata = data_load(data='train')\n",
    "        self.testdata = data_load(data='test')\n",
    "        self.topology = topology\n",
    "        self.use_langevin_gradients = use_langevin_gradients\n",
    "        self.batch_size = batch_size\n",
    "        self.l_prob=0.5\n",
    "        # ----------------\n",
    "\n",
    "    def rmse(self, predictions, targets):\n",
    "        return self.rnn.los.item()\n",
    "\n",
    "    def likelihood_func(self, rnn, data, w=None):\n",
    "        y = torch.zeros((len(data), 16))#self.batch_size))\n",
    "        for i, dat in enumerate(data, 0):\n",
    "            inputs, labels = dat\n",
    "            labels = labels.view(labels.size(0)).type(torch.LongTensor)\n",
    "            if(labels.size(0)==16):\n",
    "                y[i] = labels\n",
    "        if w is not None:\n",
    "            fx, prob = rnn.evaluate_proposal(data, w)\n",
    "        else:\n",
    "            fx, prob = rnn.evaluate_proposal(data)\n",
    "        # rmse = self.rmse(fx,y)\n",
    "        rmse = copy.deepcopy(self.rnn.los) / len(data)\n",
    "        lhood = 0\n",
    "        for i in range(len(data)):\n",
    "            for j in range(self.batch_size):\n",
    "                for k in range(self.topology[2]):\n",
    "                    if k == y[i][j]:\n",
    "                        if prob[i,j,k] == 0:\n",
    "                            lhood+=0\n",
    "                        else:\n",
    "                            lhood += np.log(prob[i, j, k])\n",
    "        return [lhood, fx, rmse]\n",
    "\n",
    "    def prior_likelihood(self, sigma_squared, w_list):\n",
    "        part1 = -1 * ((len(w_list)) / 2) * np.log(sigma_squared)\n",
    "        part2 = 1 / (2 * sigma_squared) * (sum(np.square(w_list)))\n",
    "        log_loss = part1 - part2\n",
    "        return log_loss\n",
    "\n",
    "\n",
    "    def accuracy(self, data):\n",
    "        # Test the model\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in data:\n",
    "            # images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = self.rnn(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        return 100 * correct / total\n",
    "\n",
    "\n",
    "    def sampler(self):\n",
    "        samples = self.samples\n",
    "        rnn = self.rnn\n",
    "        w = rnn.state_dict()\n",
    "        w_size = len(rnn.getparameters(w))\n",
    "        rmse_train = np.zeros(samples)\n",
    "        rmse_test = np.zeros(samples)\n",
    "        acc_train = np.zeros(samples)\n",
    "        acc_test = np.zeros(samples)\n",
    "\n",
    "        likelihood_proposal_array = np.zeros(samples)\n",
    "        likelihood_array=np.zeros(samples)\n",
    "        diff_likelihood_array=np.zeros(samples)\n",
    "        weight_array=np.zeros(samples)\n",
    "        weight_array1=np.zeros(samples)\n",
    "        weight_array2=np.zeros(samples)\n",
    "        sum_value_array=np.zeros(samples)\n",
    "\n",
    "\n",
    "        eta = 0\n",
    "        w_proposal = np.random.randn(w_size)\n",
    "        w_proposal = rnn.dictfromlist(w_proposal)\n",
    "        step_w = 0.05\n",
    "        train = self.traindata  # data_load(data='train')\n",
    "        test = self.testdata  # data_load(data= 'test')\n",
    "        sigma_squared = 25#25\n",
    "        nu_1 = 0\n",
    "        nu_2 = 0\n",
    "        delta_likelihood = 0.5  # an arbitrary position\n",
    "        prior_current = self.prior_likelihood(sigma_squared, rnn.getparameters(w))\n",
    "\n",
    "\n",
    "        [likelihood, pred_train, rmsetrain] = self.likelihood_func(rnn, train)\n",
    "        [_, pred_test, rmsetest] = self.likelihood_func(rnn, test)\n",
    "\n",
    "        # Beginning Sampling using MCMC RANDOMWALK\n",
    "        y_test = torch.zeros((len(test), self.batch_size))\n",
    "        for i, dat in enumerate(test, 0):\n",
    "            inputs, labels = dat\n",
    "            if(labels.size(0)==16):\n",
    "                y_test[i] = copy.deepcopy(labels.view(labels.size(0)).type(torch.LongTensor))\n",
    "        y_train = torch.zeros((len(train), self.batch_size))\n",
    "        for i, dat in enumerate(train, 0):\n",
    "            inputs, labels = dat\n",
    "            if(labels.size(0)==16):\n",
    "                y_train[i] = copy.deepcopy(labels.view(labels.size(0)).type(torch.LongTensor))\n",
    "\n",
    "        trainacc = 0\n",
    "        testacc = 0\n",
    "\n",
    "        num_accepted = 0\n",
    "        langevin_count = 0\n",
    "        init_count = 0\n",
    "        rmse_train[0] = rmsetrain\n",
    "        rmse_test[0] = rmsetest\n",
    "        acc_train[0] = self.accuracy(train)\n",
    "        acc_test[0] = self.accuracy(test)\n",
    "        likelihood_proposal_array[0]=0\n",
    "        likelihood_array[0]=0\n",
    "        diff_likelihood_array[0]=0\n",
    "        weight_array[0]=0\n",
    "        weight_array1[0] = 0\n",
    "        weight_array2[0] = 0\n",
    "        sum_value_array[0]=0\n",
    "\n",
    "        #pytorch_total_params = sum(p.numel() for p in rnn.parameters() if p.requires_grad)\n",
    "        #print(pytorch_total_params)\n",
    "        # acc_train[0] = 50.0\n",
    "        # acc_test[0] = 50.0\n",
    "\n",
    "        # print('i and samples')\n",
    "        print(\"beginning sampling\")\n",
    "        import time\n",
    "        start = time.time()\n",
    "        for i in range(samples):  # Begin sampling --------------------------------------------------------------------------\n",
    "\n",
    "            lx = np.random.uniform(0, 1, 1)\n",
    "            old_w = rnn.state_dict()\n",
    "            #and (lx < self.l_prob)\n",
    "            if (self.use_langevin_gradients is True) and (lx < self.l_prob):\n",
    "                w_gd = rnn.langevin_gradient(train)  # Eq 8\n",
    "                w_proposal = rnn.addnoiseandcopy(0, step_w)  # np.random.normal(w_gd, step_w, w_size) # Eq 7\n",
    "                w_prop_gd = rnn.langevin_gradient(train)\n",
    "                wc_delta = (rnn.getparameters(w) - rnn.getparameters(w_prop_gd))\n",
    "                wp_delta = (rnn.getparameters(w_proposal) - rnn.getparameters(w_gd))\n",
    "                sigma_sq = step_w\n",
    "                first = -0.5 * np.sum(wc_delta * wc_delta) / sigma_sq  # this is wc_delta.T  *  wc_delta /sigma_sq\n",
    "                second = -0.5 * np.sum(wp_delta * wp_delta) / sigma_sq\n",
    "                diff_prop = first - second\n",
    "                diff_prop = diff_prop\n",
    "                langevin_count = langevin_count + 1\n",
    "            else:\n",
    "                diff_prop = 0\n",
    "                w_proposal = rnn.addnoiseandcopy(0, step_w)  # np.random.normal(w, step_w, w_size)\n",
    "\n",
    "\n",
    "            [likelihood_proposal, pred_train, rmsetrain] = self.likelihood_func(rnn, train)\n",
    "            [likelihood_ignore, pred_test, rmsetest] = self.likelihood_func(rnn, test)\n",
    "\n",
    "\n",
    "\n",
    "            prior_prop = self.prior_likelihood(sigma_squared, rnn.getparameters(w_proposal))  # takes care of the gradients\n",
    "\n",
    "            diff_likelihood = likelihood_proposal - likelihood\n",
    "            #diff_likelihood = diff_likelihood*-1\n",
    "            diff_prior = prior_prop - prior_current\n",
    "\n",
    "            likelihood_proposal_array[i] = likelihood_proposal\n",
    "            likelihood_array[i] = likelihood\n",
    "            diff_likelihood_array[i] = diff_likelihood\n",
    "\n",
    "\n",
    "\n",
    "            #print(\"\\n\\n\")\n",
    "            #print(\"Likelihood Proposal\")\n",
    "            #print(likelihood_proposal)\n",
    "            #print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "            #print(\"\\n\\n\")\n",
    "            #print(\"Likelihood\")\n",
    "            #print(likelihood)\n",
    "            #print(\"\\n\\n\")\n",
    "\n",
    "            #print(\"Diff_Likelihood\")\n",
    "            #print(diff_likelihood)\n",
    "            #print(\"\\n\\n\")\n",
    "\n",
    "            #print(\"Diff_Prior\")\n",
    "            #print(diff_prior)\n",
    "            #print(\"\\n\\n\")\n",
    "\n",
    "            #print(\"Diff_Prop\")\n",
    "            #print(diff_prop)\n",
    "            #print(\"\\n\\n\")\n",
    "\n",
    "            #print(\"Sum Number\")\n",
    "            #print(diff_likelihood + diff_prior + diff_prop)\n",
    "            #print(\"\\n\\n\")\n",
    "            #+ diff_prior + diff_prop\n",
    "\n",
    "            #try:\n",
    "            #    mh_prob = min(1, math.exp(diff_likelihood))\n",
    "            #except OverflowError as e:\n",
    "            #    mh_prob = 1\n",
    "\n",
    "            sum_value=diff_likelihood + diff_prior + diff_prop\n",
    "            u = np.log(random.uniform(0, 1))\n",
    "\n",
    "            sum_value_array[i]=sum_value\n",
    "\n",
    "            #print(\"Sum_Value\")\n",
    "            #print(sum_value)\n",
    "            #print(\"\\n\\n\")\n",
    "\n",
    "            #print(\"U\")\n",
    "            #print(u)\n",
    "            #print(\"\\n\\n\")\n",
    "            #print(\"MH_Prob\")\n",
    "            #print(mh_prob)\n",
    "            #print(\"\\n\\n\")\n",
    "\n",
    "            if u < sum_value:\n",
    "                num_accepted = num_accepted + 1\n",
    "                likelihood = likelihood_proposal\n",
    "                prior_current = prior_prop\n",
    "                w = copy.deepcopy(w_proposal)  # rnn.getparameters(w_proposal)\n",
    "                acc_train1 = self.accuracy(train)\n",
    "                acc_test1 = self.accuracy(test)\n",
    "                print (i, rmsetrain, rmsetest, acc_train1, acc_test1, 'accepted')\n",
    "                rmse_train[i] = rmsetrain\n",
    "                rmse_test[i] = rmsetest\n",
    "                acc_train[i,] = acc_train1\n",
    "                acc_test[i,] = acc_test1\n",
    "\n",
    "            else:\n",
    "                w = old_w\n",
    "                rnn.loadparameters(w)\n",
    "                acc_train1 = self.accuracy(train)\n",
    "                acc_test1 = self.accuracy(test)\n",
    "                print (i, rmsetrain, rmsetest, acc_train1, acc_test1, 'rejected')\n",
    "                #rmse_train[i] = rmsetrain\n",
    "                #rmse_test[i] = rmsetest\n",
    "                #acc_train[i,] = acc_train1\n",
    "                #acc_test[i,] = acc_test1\n",
    "                rmse_train[i,] = rmse_train[i - 1,]\n",
    "                rmse_test[i,] = rmse_test[i - 1,]\n",
    "                acc_train[i,] = acc_train[i - 1,]\n",
    "                acc_test[i,] = acc_test[i - 1,]\n",
    "\n",
    "            ll=rnn.getparameters()\n",
    "            #print(ll[0])\n",
    "            weight_array[i]=ll[0]\n",
    "            weight_array1[i] = ll[100]\n",
    "            weight_array2[i] = ll[50000]\n",
    "\n",
    "\n",
    "        end = time.time()\n",
    "        print(\"\\n\\nTotal time taken for Sampling : \", (end-start))\n",
    "        print ((num_accepted * 100 / (samples * 1.0)), '% was Accepted')\n",
    "\n",
    "        print ((langevin_count * 100 / (samples * 1.0)), '% was Langevin')\n",
    "\n",
    "        return acc_train, acc_test, rmse_train, rmse_test, sum_value_array, weight_array, weight_array1, weight_array2\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    outres = open('resultspriors.txt', 'w')\n",
    "\n",
    "    topology = [input_size, hidden_size, num_classes]\n",
    "\n",
    "    numSamples = 100\n",
    "    ulg = True\n",
    "\n",
    "    learnr=0.01\n",
    "    burnin =0.25\n",
    "\n",
    "\n",
    "    mcmc = MCMC(numSamples, topology, ulg, learnr, batch_size)  # declare class\n",
    "    acc_train, acc_test, rmse_train, rmse_test, sva, wa, wa1, wa2 = mcmc.sampler()\n",
    "\n",
    "    acc_train=acc_train[int(numSamples*burnin):]\n",
    "    #print(acc_train)\n",
    "    acc_test=acc_test[int(numSamples*burnin):]\n",
    "    print(\"\\nShape of acc_test : \",acc_test.shape)\n",
    "    rmse_train=rmse_train[int(numSamples*burnin):]\n",
    "    rmse_test=rmse_test[int(numSamples*burnin):]\n",
    "    sva=sva[int(numSamples*burnin):]\n",
    "    print(\"\\nShape of sva : \",sva.shape)\n",
    "    print(\"\\nShape of wa : \",wa.shape)\n",
    "    print(\"\\nShape of wa1 : \",wa1.shape)\n",
    "    print(\"\\nShape of wa2 : \",wa2.shape)\n",
    "    \n",
    "    #print(lpa)\n",
    "\n",
    "    print(\"\\n\\n\\n\\n\\n\\n\\n\\n\")\n",
    "    print(\"Mean of RMSE Train\")\n",
    "    print(np.mean(rmse_train))\n",
    "    print(\"\\n\")\n",
    "    print(\"Mean of Accuracy Train\")\n",
    "    print(np.mean(acc_train))\n",
    "    print(\"\\n\")\n",
    "    print(\"Mean of RMSE Test\")\n",
    "    print(np.mean(rmse_test))\n",
    "    print(\"\\n\")\n",
    "    print(\"Mean of Accuracy Test\")\n",
    "    print(np.mean(acc_test))\n",
    "    print ('sucessfully sampled')\n",
    "\n",
    "    problemfolder = 'HAR_SINGLECHAIN2'\n",
    "    os.makedirs(problemfolder)\n",
    "\n",
    "\n",
    "    x = np.linspace(0, int(numSamples-numSamples*burnin), num=int(numSamples-numSamples*burnin)+1)\n",
    "    x1 = np.linspace(0, numSamples, num=numSamples)\n",
    "\n",
    "    plt.plot(x1, wa, label='Weight[0]')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title(\"Weight[0] Trace\")\n",
    "    plt.savefig('HAR_SINGLECHAIN2' + '/weight[0]_samples.png')\n",
    "    plt.clf()\n",
    "\n",
    "    plt.plot(x1, wa1, label='Weight[1]')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title(\"Weight[100] Trace\")\n",
    "    plt.savefig('HAR_SINGLECHAIN2' + '/weight[1]_samples.png')\n",
    "    plt.clf()\n",
    "\n",
    "    plt.plot(x1,wa2, label='Weight[2]')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title(\"Weight[50000] Trace\")\n",
    "    plt.savefig('HAR_SINGLECHAIN2' + '/weight[2]_samples.png')\n",
    "    plt.clf()\n",
    "\n",
    "    #plt.plot(x1, wa3, label='Weight[3]')\n",
    "    #plt.legend(loc='upper right')\n",
    "    #plt.title(\"Weight[10000] Trace\")\n",
    "    #plt.savefig('HAR_SINGLECHAIN' + '/weight[3]_samples.png')\n",
    "    #plt.clf()\n",
    "\n",
    "    plt.plot(x, sva, label='Sum_Value')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title(\"Sum Value Over Samples\")\n",
    "    plt.savefig('HAR_SINGLECHAIN2'+'/sum_value_samples.png')\n",
    "    plt.clf()\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    color = 'tab:red'\n",
    "    ax1.set_xlabel('Samples')\n",
    "    ax1.set_ylabel('Accuracy Train', color=color)\n",
    "    ax1.plot(x, acc_train, color=color)\n",
    "    ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "    color = 'tab:blue'\n",
    "    ax2.set_ylabel('Accuracy Test', color=color)  # we already handled the x-label with ax1\n",
    "    ax2.plot(x, acc_test, color=color)\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "\n",
    "    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "    plt.savefig('HAR_SINGLECHAIN2' + '/superimposed_acc.png')\n",
    "    plt.clf()\n",
    "\n",
    "    fig1, ax4 = plt.subplots()\n",
    "\n",
    "    color = 'tab:red'\n",
    "    ax4.set_xlabel('Samples')\n",
    "    ax4.set_ylabel('RMSE Train', color=color)\n",
    "    ax4.plot(x, rmse_train, color=color)\n",
    "    ax4.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    ax5 = ax4.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "    color = 'tab:blue'\n",
    "    ax5.set_ylabel('RMSE Test', color=color)  # we already handled the x-label with ax1\n",
    "    ax5.plot(x, rmse_test, color=color)\n",
    "    ax5.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "\n",
    "    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "    plt.savefig('HAR_SINGLECHAIN2' + '/superimposed_rmse.png')\n",
    "    plt.clf()\n",
    "    \n",
    "    plt.hist(wa)\n",
    "    plt.hist(wa1)\n",
    "    plt.hist(wa2)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\": main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "printable-pottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plots():\n",
    "    problemfolder = 'HAR_SINGLECHAIN'\n",
    "    os.makedirs(problemfolder)\n",
    "\n",
    "\n",
    "    x = np.linspace(0, int(numSamples-numSamples*burnin), num=int(numSamples-numSamples*burnin))\n",
    "    x1 = np.linspace(0, numSamples, num=numSamples)\n",
    "\n",
    "    plt.plot(x1, wa, label='Weight[0]')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title(\"Weight[0] Trace\")\n",
    "    plt.savefig('mnist_torch_single_chain' + '/weight[0]_samples.png')\n",
    "    plt.clf()\n",
    "\n",
    "    plt.plot(x1, wa1, label='Weight[100]')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title(\"Weight[100] Trace\")\n",
    "    plt.savefig('mnist_torch_single_chain' + '/weight[100]_samples.png')\n",
    "    plt.clf()\n",
    "\n",
    "    plt.plot(x1,wa2, label='Weight[50000]')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title(\"Weight[50000] Trace\")\n",
    "    plt.savefig('mnist_torch_single_chain' + '/weight[50000]_samples.png')\n",
    "    plt.clf()\n",
    "\n",
    "    plt.plot(x, sva, label='Sum_Value')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title(\"Sum Value Over Samples\")\n",
    "    plt.savefig('mnist_torch_single_chain'+'/sum_value_samples.png')\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "    #plt.plot(x, acc_train, label='Train')\n",
    "    #plt.legend(loc='upper right')\n",
    "    #plt.title(\"Accuracy Train Values Over Samples\")\n",
    "    #plt.savefig('mnist_torch_single_chain' + '/accuracy_samples.png')\n",
    "    #plt.clf()\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    color = 'tab:red'\n",
    "    ax1.set_xlabel('Samples')\n",
    "    ax1.set_ylabel('Accuracy Train', color=color)\n",
    "    ax1.plot(x, acc_train, color=color)\n",
    "    ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "    color = 'tab:blue'\n",
    "    ax2.set_ylabel('Accuracy Test', color=color)  # we already handled the x-label with ax1\n",
    "    ax2.plot(x, acc_test, color=color)\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    #ax3=ax1.twinx()\n",
    "\n",
    "    #color = 'tab:green'\n",
    "    #ax3.set_ylabel('Accuracy Test', color=color)  # we already handled the x-label with ax1\n",
    "    #ax3.plot(x, acc_test, color=color)\n",
    "    #ax3.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "    plt.savefig('mnist_torch_single_chain' + '/superimposed_acc.png')\n",
    "    plt.clf()\n",
    "\n",
    "    fig1, ax4 = plt.subplots()\n",
    "\n",
    "    color = 'tab:red'\n",
    "    ax4.set_xlabel('Samples')\n",
    "    ax4.set_ylabel('RMSE Train', color=color)\n",
    "    ax4.plot(x, rmse_train, color=color)\n",
    "    ax4.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    ax5 = ax4.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "    color = 'tab:blue'\n",
    "    ax5.set_ylabel('RMSE Test', color=color)  # we already handled the x-label with ax1\n",
    "    ax5.plot(x, rmse_test, color=color)\n",
    "    ax5.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    #ax6 = ax4.twinx()\n",
    "\n",
    "    #color = 'tab:green'\n",
    "    #ax6.set_ylabel('RMSE Test', color=color)  # we already handled the x-label with ax1\n",
    "    #ax6.plot(x, rmse_test, color=color)\n",
    "    #ax6.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "    plt.savefig('mnist_torch_single_chain' + '/superimposed_rmse.png')\n",
    "    plt.clf()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "assured-regulation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "assumed-sender",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = data_load('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "hidden-thread",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([2., 2., 2., 5., 3., 5., 2., 2., 4., 0., 1., 2., 1., 5., 5., 4.])\n",
      "torch.Size([16])\n",
      "tensor([2, 2, 2, 5, 3, 5, 2, 2, 4, 0, 1, 2, 1, 5, 5, 4])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([2., 4., 4., 0., 5., 4., 1., 1., 0., 4., 1., 3., 1., 5., 0., 1.])\n",
      "torch.Size([16])\n",
      "tensor([2, 4, 4, 0, 5, 4, 1, 1, 0, 4, 1, 3, 1, 5, 0, 1])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([4., 5., 0., 1., 4., 4., 3., 4., 5., 4., 4., 0., 1., 1., 4., 5.])\n",
      "torch.Size([16])\n",
      "tensor([4, 5, 0, 1, 4, 4, 3, 4, 5, 4, 4, 0, 1, 1, 4, 5])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([4., 0., 3., 4., 3., 5., 4., 3., 5., 4., 1., 4., 0., 4., 1., 4.])\n",
      "torch.Size([16])\n",
      "tensor([4, 0, 3, 4, 3, 5, 4, 3, 5, 4, 1, 4, 0, 4, 1, 4])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([1., 3., 4., 2., 5., 5., 3., 4., 0., 5., 1., 3., 2., 1., 5., 0.])\n",
      "torch.Size([16])\n",
      "tensor([1, 3, 4, 2, 5, 5, 3, 4, 0, 5, 1, 3, 2, 1, 5, 0])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([3., 4., 0., 4., 3., 4., 5., 4., 4., 2., 4., 4., 3., 2., 4., 0.])\n",
      "torch.Size([16])\n",
      "tensor([3, 4, 0, 4, 3, 4, 5, 4, 4, 2, 4, 4, 3, 2, 4, 0])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([5., 3., 0., 3., 2., 4., 3., 3., 0., 0., 4., 3., 1., 0., 0., 5.])\n",
      "torch.Size([16])\n",
      "tensor([5, 3, 0, 3, 2, 4, 3, 3, 0, 0, 4, 3, 1, 0, 0, 5])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([2., 5., 3., 4., 1., 4., 1., 0., 5., 1., 3., 2., 0., 5., 5., 1.])\n",
      "torch.Size([16])\n",
      "tensor([2, 5, 3, 4, 1, 4, 1, 0, 5, 1, 3, 2, 0, 5, 5, 1])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([0., 5., 3., 1., 5., 2., 3., 3., 1., 5., 4., 4., 5., 3., 0., 0.])\n",
      "torch.Size([16])\n",
      "tensor([0, 5, 3, 1, 5, 2, 3, 3, 1, 5, 4, 4, 5, 3, 0, 0])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([2., 2., 5., 1., 1., 3., 2., 4., 4., 3., 3., 1., 4., 1., 1., 3.])\n",
      "torch.Size([16])\n",
      "tensor([2, 2, 5, 1, 1, 3, 2, 4, 4, 3, 3, 1, 4, 1, 1, 3])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([2., 4., 0., 4., 0., 3., 4., 4., 1., 5., 4., 4., 5., 5., 4., 3.])\n",
      "torch.Size([16])\n",
      "tensor([2, 4, 0, 4, 0, 3, 4, 4, 1, 5, 4, 4, 5, 5, 4, 3])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([3., 0., 2., 0., 2., 5., 2., 4., 1., 1., 1., 3., 0., 2., 3., 1.])\n",
      "torch.Size([16])\n",
      "tensor([3, 0, 2, 0, 2, 5, 2, 4, 1, 1, 1, 3, 0, 2, 3, 1])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([4., 3., 1., 2., 3., 2., 5., 3., 3., 5., 2., 4., 4., 5., 0., 1.])\n",
      "torch.Size([16])\n",
      "tensor([4, 3, 1, 2, 3, 2, 5, 3, 3, 5, 2, 4, 4, 5, 0, 1])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([2., 1., 5., 3., 3., 0., 3., 3., 0., 1., 4., 0., 5., 5., 2., 5.])\n",
      "torch.Size([16])\n",
      "tensor([2, 1, 5, 3, 3, 0, 3, 3, 0, 1, 4, 0, 5, 5, 2, 5])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([0., 1., 3., 5., 3., 2., 2., 5., 5., 3., 0., 5., 4., 5., 4., 4.])\n",
      "torch.Size([16])\n",
      "tensor([0, 1, 3, 5, 3, 2, 2, 5, 5, 3, 0, 5, 4, 5, 4, 4])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([3., 0., 1., 0., 4., 4., 5., 5., 2., 1., 1., 0., 0., 5., 5., 3.])\n",
      "torch.Size([16])\n",
      "tensor([3, 0, 1, 0, 4, 4, 5, 5, 2, 1, 1, 0, 0, 5, 5, 3])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([5., 2., 4., 3., 1., 1., 4., 4., 5., 2., 4., 0., 5., 0., 5., 0.])\n",
      "torch.Size([16])\n",
      "tensor([5, 2, 4, 3, 1, 1, 4, 4, 5, 2, 4, 0, 5, 0, 5, 0])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([4., 1., 2., 4., 0., 1., 2., 3., 4., 0., 5., 0., 0., 1., 3., 2.])\n",
      "torch.Size([16])\n",
      "tensor([4, 1, 2, 4, 0, 1, 2, 3, 4, 0, 5, 0, 0, 1, 3, 2])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([1., 1., 2., 5., 2., 2., 0., 5., 2., 2., 0., 0., 3., 0., 4., 3.])\n",
      "torch.Size([16])\n",
      "tensor([1, 1, 2, 5, 2, 2, 0, 5, 2, 2, 0, 0, 3, 0, 4, 3])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([0., 5., 1., 1., 4., 2., 1., 4., 2., 5., 3., 5., 5., 5., 5., 5.])\n",
      "torch.Size([16])\n",
      "tensor([0, 5, 1, 1, 4, 2, 1, 4, 2, 5, 3, 5, 5, 5, 5, 5])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([3., 0., 1., 1., 0., 4., 1., 1., 5., 5., 3., 0., 4., 5., 2., 0.])\n",
      "torch.Size([16])\n",
      "tensor([3, 0, 1, 1, 0, 4, 1, 1, 5, 5, 3, 0, 4, 5, 2, 0])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([1., 0., 0., 0., 3., 5., 5., 2., 3., 1., 4., 5., 4., 5., 1., 3.])\n",
      "torch.Size([16])\n",
      "tensor([1, 0, 0, 0, 3, 5, 5, 2, 3, 1, 4, 5, 4, 5, 1, 3])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([3., 4., 2., 4., 0., 4., 0., 4., 3., 0., 1., 4., 3., 3., 0., 2.])\n",
      "torch.Size([16])\n",
      "tensor([3, 4, 2, 4, 0, 4, 0, 4, 3, 0, 1, 4, 3, 3, 0, 2])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([1., 4., 2., 2., 4., 0., 3., 5., 3., 0., 3., 1., 4., 3., 3., 5.])\n",
      "torch.Size([16])\n",
      "tensor([1, 4, 2, 2, 4, 0, 3, 5, 3, 0, 3, 1, 4, 3, 3, 5])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([2., 3., 4., 3., 4., 4., 3., 0., 2., 5., 0., 5., 3., 3., 5., 1.])\n",
      "torch.Size([16])\n",
      "tensor([2, 3, 4, 3, 4, 4, 3, 0, 2, 5, 0, 5, 3, 3, 5, 1])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([5., 1., 1., 2., 2., 1., 2., 0., 4., 4., 3., 4., 1., 1., 2., 3.])\n",
      "torch.Size([16])\n",
      "tensor([5, 1, 1, 2, 2, 1, 2, 0, 4, 4, 3, 4, 1, 1, 2, 3])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([1., 4., 1., 4., 3., 5., 1., 5., 0., 1., 0., 4., 2., 2., 1., 5.])\n",
      "torch.Size([16])\n",
      "tensor([1, 4, 1, 4, 3, 5, 1, 5, 0, 1, 0, 4, 2, 2, 1, 5])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([2., 5., 5., 5., 1., 4., 4., 4., 3., 0., 4., 5., 4., 0., 2., 5.])\n",
      "torch.Size([16])\n",
      "tensor([2, 5, 5, 5, 1, 4, 4, 4, 3, 0, 4, 5, 4, 0, 2, 5])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([2., 1., 3., 2., 5., 0., 4., 2., 4., 0., 5., 5., 3., 2., 4., 0.])\n",
      "torch.Size([16])\n",
      "tensor([2, 1, 3, 2, 5, 0, 4, 2, 4, 0, 5, 5, 3, 2, 4, 0])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([0., 2., 3., 5., 4., 4., 3., 3., 2., 1., 4., 0., 1., 5., 5., 4.])\n",
      "torch.Size([16])\n",
      "tensor([0, 2, 3, 5, 4, 4, 3, 3, 2, 1, 4, 0, 1, 5, 5, 4])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([2., 3., 4., 4., 5., 3., 4., 5., 4., 0., 1., 3., 1., 5., 3., 2.])\n",
      "torch.Size([16])\n",
      "tensor([2, 3, 4, 4, 5, 3, 4, 5, 4, 0, 1, 3, 1, 5, 3, 2])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([3., 1., 4., 4., 5., 1., 1., 0., 1., 1., 1., 1., 3., 0., 3., 0.])\n",
      "torch.Size([16])\n",
      "tensor([3, 1, 4, 4, 5, 1, 1, 0, 1, 1, 1, 1, 3, 0, 3, 0])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([4., 1., 5., 5., 5., 1., 0., 4., 2., 4., 5., 2., 2., 5., 4., 3.])\n",
      "torch.Size([16])\n",
      "tensor([4, 1, 5, 5, 5, 1, 0, 4, 2, 4, 5, 2, 2, 5, 4, 3])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([1., 3., 4., 5., 4., 1., 3., 0., 0., 0., 4., 2., 1., 3., 1., 4.])\n",
      "torch.Size([16])\n",
      "tensor([1, 3, 4, 5, 4, 1, 3, 0, 0, 0, 4, 2, 1, 3, 1, 4])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([4., 1., 5., 4., 0., 3., 3., 0., 3., 2., 4., 1., 0., 0., 4., 5.])\n",
      "torch.Size([16])\n",
      "tensor([4, 1, 5, 4, 0, 3, 3, 0, 3, 2, 4, 1, 0, 0, 4, 5])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([4., 2., 2., 2., 0., 5., 4., 3., 4., 5., 5., 0., 2., 2., 0., 5.])\n",
      "torch.Size([16])\n",
      "tensor([4, 2, 2, 2, 0, 5, 4, 3, 4, 5, 5, 0, 2, 2, 0, 5])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([2., 2., 1., 3., 1., 3., 2., 4., 1., 4., 0., 0., 0., 5., 2., 5.])\n",
      "torch.Size([16])\n",
      "tensor([2, 2, 1, 3, 1, 3, 2, 4, 1, 4, 0, 0, 0, 5, 2, 5])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([1., 1., 4., 4., 0., 2., 5., 5., 3., 0., 4., 1., 0., 5., 4., 1.])\n",
      "torch.Size([16])\n",
      "tensor([1, 1, 4, 4, 0, 2, 5, 5, 3, 0, 4, 1, 0, 5, 4, 1])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([0., 0., 0., 1., 4., 0., 0., 0., 3., 4., 5., 3., 5., 3., 2., 0.])\n",
      "torch.Size([16])\n",
      "tensor([0, 0, 0, 1, 4, 0, 0, 0, 3, 4, 5, 3, 5, 3, 2, 0])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([3., 3., 1., 0., 5., 1., 1., 1., 0., 0., 3., 4., 5., 0., 3., 3.])\n",
      "torch.Size([16])\n",
      "tensor([3, 3, 1, 0, 5, 1, 1, 1, 0, 0, 3, 4, 5, 0, 3, 3])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([3., 1., 4., 4., 2., 0., 5., 0., 1., 0., 4., 0., 5., 3., 5., 5.])\n",
      "torch.Size([16])\n",
      "tensor([3, 1, 4, 4, 2, 0, 5, 0, 1, 0, 4, 0, 5, 3, 5, 5])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([0., 4., 1., 3., 5., 5., 1., 5., 3., 3., 0., 0., 2., 0., 3., 1.])\n",
      "torch.Size([16])\n",
      "tensor([0, 4, 1, 3, 5, 5, 1, 5, 3, 3, 0, 0, 2, 0, 3, 1])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([3., 2., 2., 2., 4., 5., 4., 0., 3., 5., 0., 1., 4., 4., 5., 5.])\n",
      "torch.Size([16])\n",
      "tensor([3, 2, 2, 2, 4, 5, 4, 0, 3, 5, 0, 1, 4, 4, 5, 5])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([5., 0., 4., 2., 4., 1., 2., 1., 0., 1., 0., 5., 3., 4., 5., 4.])\n",
      "torch.Size([16])\n",
      "tensor([5, 0, 4, 2, 4, 1, 2, 1, 0, 1, 0, 5, 3, 4, 5, 4])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([0., 0., 4., 3., 4., 0., 1., 0., 5., 3., 0., 4., 4., 0., 2., 0.])\n",
      "torch.Size([16])\n",
      "tensor([0, 0, 4, 3, 4, 0, 1, 0, 5, 3, 0, 4, 4, 0, 2, 0])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([1., 5., 5., 4., 4., 0., 1., 5., 1., 4., 4., 4., 5., 5., 1., 5.])\n",
      "torch.Size([16])\n",
      "tensor([1, 5, 5, 4, 4, 0, 1, 5, 1, 4, 4, 4, 5, 5, 1, 5])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([1., 2., 4., 2., 2., 0., 1., 3., 3., 5., 4., 4., 2., 0., 2., 1.])\n",
      "torch.Size([16])\n",
      "tensor([1, 2, 4, 2, 2, 0, 1, 3, 3, 5, 4, 4, 2, 0, 2, 1])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([2., 2., 1., 1., 5., 5., 1., 3., 4., 1., 2., 4., 5., 3., 0., 4.])\n",
      "torch.Size([16])\n",
      "tensor([2, 2, 1, 1, 5, 5, 1, 3, 4, 1, 2, 4, 5, 3, 0, 4])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([0., 2., 4., 3., 0., 2., 2., 1., 0., 2., 2., 4., 2., 5., 2., 3.])\n",
      "torch.Size([16])\n",
      "tensor([0, 2, 4, 3, 0, 2, 2, 1, 0, 2, 2, 4, 2, 5, 2, 3])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([0., 3., 4., 4., 2., 3., 2., 5., 0., 3., 1., 0., 1., 1., 4., 1.])\n",
      "torch.Size([16])\n",
      "tensor([0, 3, 4, 4, 2, 3, 2, 5, 0, 3, 1, 0, 1, 1, 4, 1])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([4., 3., 1., 3., 4., 2., 0., 2., 3., 0., 1., 2., 5., 0., 5., 2.])\n",
      "torch.Size([16])\n",
      "tensor([4, 3, 1, 3, 4, 2, 0, 2, 3, 0, 1, 2, 5, 0, 5, 2])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([4., 1., 5., 4., 4., 5., 4., 0., 3., 4., 2., 5., 3., 3., 0., 4.])\n",
      "torch.Size([16])\n",
      "tensor([4, 1, 5, 4, 4, 5, 4, 0, 3, 4, 2, 5, 3, 3, 0, 4])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([0., 1., 5., 4., 1., 3., 2., 4., 0., 1., 3., 0., 0., 2., 5., 3.])\n",
      "torch.Size([16])\n",
      "tensor([0, 1, 5, 4, 1, 3, 2, 4, 0, 1, 3, 0, 0, 2, 5, 3])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([4., 2., 5., 3., 3., 0., 0., 2., 0., 5., 0., 4., 0., 3., 1., 5.])\n",
      "torch.Size([16])\n",
      "tensor([4, 2, 5, 3, 3, 0, 0, 2, 0, 5, 0, 4, 0, 3, 1, 5])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([0., 1., 5., 0., 3., 2., 2., 2., 2., 1., 0., 4., 1., 3., 4., 5.])\n",
      "torch.Size([16])\n",
      "tensor([0, 1, 5, 0, 3, 2, 2, 2, 2, 1, 0, 4, 1, 3, 4, 5])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([1., 1., 2., 1., 3., 3., 0., 5., 2., 1., 4., 4., 5., 3., 4., 0.])\n",
      "torch.Size([16])\n",
      "tensor([1, 1, 2, 1, 3, 3, 0, 5, 2, 1, 4, 4, 5, 3, 4, 0])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([3., 1., 3., 0., 1., 2., 0., 5., 4., 0., 1., 3., 4., 5., 5., 4.])\n",
      "torch.Size([16])\n",
      "tensor([3, 1, 3, 0, 1, 2, 0, 5, 4, 0, 1, 3, 4, 5, 5, 4])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([0., 3., 3., 4., 0., 5., 2., 2., 0., 0., 1., 2., 1., 0., 1., 5.])\n",
      "torch.Size([16])\n",
      "tensor([0, 3, 3, 4, 0, 5, 2, 2, 0, 0, 1, 2, 1, 0, 1, 5])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([5., 4., 5., 0., 2., 5., 5., 2., 4., 0., 5., 3., 4., 3., 3., 5.])\n",
      "torch.Size([16])\n",
      "tensor([5, 4, 5, 0, 2, 5, 5, 2, 4, 0, 5, 3, 4, 3, 3, 5])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([5., 3., 5., 2., 4., 1., 3., 1., 5., 2., 2., 3., 5., 3., 4., 4.])\n",
      "torch.Size([16])\n",
      "tensor([5, 3, 5, 2, 4, 1, 3, 1, 5, 2, 2, 3, 5, 3, 4, 4])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([2., 2., 3., 5., 3., 1., 2., 5., 0., 4., 0., 0., 5., 2., 0., 4.])\n",
      "torch.Size([16])\n",
      "tensor([2, 2, 3, 5, 3, 1, 2, 5, 0, 4, 0, 0, 5, 2, 0, 4])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([1., 1., 1., 2., 4., 2., 3., 0., 5., 2., 3., 0., 1., 1., 2., 2.])\n",
      "torch.Size([16])\n",
      "tensor([1, 1, 1, 2, 4, 2, 3, 0, 5, 2, 3, 0, 1, 1, 2, 2])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([0., 1., 5., 2., 2., 4., 5., 1., 2., 4., 3., 3., 4., 2., 3., 5.])\n",
      "torch.Size([16])\n",
      "tensor([0, 1, 5, 2, 2, 4, 5, 1, 2, 4, 3, 3, 4, 2, 3, 5])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([1., 3., 2., 5., 3., 4., 3., 0., 3., 3., 0., 4., 4., 4., 4., 0.])\n",
      "torch.Size([16])\n",
      "tensor([1, 3, 2, 5, 3, 4, 3, 0, 3, 3, 0, 4, 4, 4, 4, 0])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([3., 5., 0., 1., 1., 4., 0., 3., 1., 1., 4., 5., 0., 0., 4., 5.])\n",
      "torch.Size([16])\n",
      "tensor([3, 5, 0, 1, 1, 4, 0, 3, 1, 1, 4, 5, 0, 0, 4, 5])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([4., 5., 0., 3., 5., 4., 4., 4., 3., 2., 5., 2., 4., 1., 5., 0.])\n",
      "torch.Size([16])\n",
      "tensor([4, 5, 0, 3, 5, 4, 4, 4, 3, 2, 5, 2, 4, 1, 5, 0])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([5., 0., 4., 2., 0., 0., 5., 5., 5., 5., 4., 0., 1., 5., 0., 0.])\n",
      "torch.Size([16])\n",
      "tensor([5, 0, 4, 2, 0, 0, 5, 5, 5, 5, 4, 0, 1, 5, 0, 0])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([4., 3., 5., 5., 0., 1., 3., 4., 3., 0., 1., 5., 2., 2., 4., 4.])\n",
      "torch.Size([16])\n",
      "tensor([4, 3, 5, 5, 0, 1, 3, 4, 3, 0, 1, 5, 2, 2, 4, 4])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([2., 1., 5., 2., 1., 4., 5., 0., 3., 2., 0., 0., 2., 0., 0., 5.])\n",
      "torch.Size([16])\n",
      "tensor([2, 1, 5, 2, 1, 4, 5, 0, 3, 2, 0, 0, 2, 0, 0, 5])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([0., 1., 3., 4., 4., 0., 1., 5., 4., 1., 3., 1., 0., 0., 0., 5.])\n",
      "torch.Size([16])\n",
      "tensor([0, 1, 3, 4, 4, 0, 1, 5, 4, 1, 3, 1, 0, 0, 0, 5])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([2., 4., 4., 1., 3., 0., 0., 3., 3., 1., 0., 5., 5., 2., 2., 4.])\n",
      "torch.Size([16])\n",
      "tensor([2, 4, 4, 1, 3, 0, 0, 3, 3, 1, 0, 5, 5, 2, 2, 4])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([2., 3., 3., 0., 3., 1., 0., 4., 0., 1., 3., 1., 3., 5., 2., 5.])\n",
      "torch.Size([16])\n",
      "tensor([2, 3, 3, 0, 3, 1, 0, 4, 0, 1, 3, 1, 3, 5, 2, 5])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([0., 5., 5., 2., 3., 1., 0., 4., 0., 0., 1., 4., 1., 5., 1., 1.])\n",
      "torch.Size([16])\n",
      "tensor([0, 5, 5, 2, 3, 1, 0, 4, 0, 0, 1, 4, 1, 5, 1, 1])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([3., 0., 0., 3., 2., 4., 3., 4., 5., 4., 5., 1., 5., 5., 5., 5.])\n",
      "torch.Size([16])\n",
      "tensor([3, 0, 0, 3, 2, 4, 3, 4, 5, 4, 5, 1, 5, 5, 5, 5])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([3., 3., 0., 0., 3., 3., 0., 1., 0., 1., 3., 1., 4., 4., 4., 1.])\n",
      "torch.Size([16])\n",
      "tensor([3, 3, 0, 0, 3, 3, 0, 1, 0, 1, 3, 1, 4, 4, 4, 1])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([5., 2., 0., 3., 1., 4., 3., 0., 2., 4., 4., 3., 5., 1., 3., 3.])\n",
      "torch.Size([16])\n",
      "tensor([5, 2, 0, 3, 1, 4, 3, 0, 2, 4, 4, 3, 5, 1, 3, 3])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([2., 0., 5., 1., 1., 4., 5., 1., 1., 4., 3., 4., 2., 3., 5., 5.])\n",
      "torch.Size([16])\n",
      "tensor([2, 0, 5, 1, 1, 4, 5, 1, 1, 4, 3, 4, 2, 3, 5, 5])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([3., 0., 3., 2., 4., 0., 1., 0., 2., 5., 4., 3., 0., 1., 0., 4.])\n",
      "torch.Size([16])\n",
      "tensor([3, 0, 3, 2, 4, 0, 1, 0, 2, 5, 4, 3, 0, 1, 0, 4])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([3., 1., 5., 1., 0., 1., 2., 3., 1., 0., 3., 1., 5., 5., 1., 4.])\n",
      "torch.Size([16])\n",
      "tensor([3, 1, 5, 1, 0, 1, 2, 3, 1, 0, 3, 1, 5, 5, 1, 4])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([3., 1., 3., 3., 5., 5., 2., 1., 2., 2., 1., 1., 5., 2., 5., 5.])\n",
      "torch.Size([16])\n",
      "tensor([3, 1, 3, 3, 5, 5, 2, 1, 2, 2, 1, 1, 5, 2, 5, 5])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([3., 5., 1., 4., 1., 5., 4., 4., 3., 2., 2., 5., 5., 3., 3., 5.])\n",
      "torch.Size([16])\n",
      "tensor([3, 5, 1, 4, 1, 5, 4, 4, 3, 2, 2, 5, 5, 3, 3, 5])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([1., 1., 0., 1., 5., 3., 4., 0., 4., 4., 2., 0., 3., 1., 4., 1.])\n",
      "torch.Size([16])\n",
      "tensor([1, 1, 0, 1, 5, 3, 4, 0, 4, 4, 2, 0, 3, 1, 4, 1])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([3., 4., 0., 2., 3., 5., 3., 4., 3., 2., 4., 2., 4., 0., 1., 4.])\n",
      "torch.Size([16])\n",
      "tensor([3, 4, 0, 2, 3, 5, 3, 4, 3, 2, 4, 2, 4, 0, 1, 4])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([1., 1., 4., 3., 5., 1., 5., 5., 5., 2., 2., 0., 2., 5., 2., 4.])\n",
      "torch.Size([16])\n",
      "tensor([1, 1, 4, 3, 5, 1, 5, 5, 5, 2, 2, 0, 2, 5, 2, 4])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([0., 0., 4., 3., 4., 5., 3., 0., 0., 4., 2., 5., 2., 0., 1., 2.])\n",
      "torch.Size([16])\n",
      "tensor([0, 0, 4, 3, 4, 5, 3, 0, 0, 4, 2, 5, 2, 0, 1, 2])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([4., 3., 4., 5., 3., 1., 0., 1., 5., 4., 1., 4., 2., 3., 0., 0.])\n",
      "torch.Size([16])\n",
      "tensor([4, 3, 4, 5, 3, 1, 0, 1, 5, 4, 1, 4, 2, 3, 0, 0])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([1., 2., 4., 3., 1., 0., 4., 0., 2., 1., 5., 0., 5., 1., 5., 3.])\n",
      "torch.Size([16])\n",
      "tensor([1, 2, 4, 3, 1, 0, 4, 0, 2, 1, 5, 0, 5, 1, 5, 3])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([0., 1., 0., 2., 0., 4., 3., 1., 0., 1., 1., 5., 0., 2., 5., 2.])\n",
      "torch.Size([16])\n",
      "tensor([0, 1, 0, 2, 0, 4, 3, 1, 0, 1, 1, 5, 0, 2, 5, 2])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([1., 5., 0., 5., 1., 3., 1., 2., 0., 5., 5., 0., 5., 0., 2., 4.])\n",
      "torch.Size([16])\n",
      "tensor([1, 5, 0, 5, 1, 3, 1, 2, 0, 5, 5, 0, 5, 0, 2, 4])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([4., 3., 5., 2., 2., 4., 1., 2., 4., 3., 4., 1., 0., 1., 5., 2.])\n",
      "torch.Size([16])\n",
      "tensor([4, 3, 5, 2, 2, 4, 1, 2, 4, 3, 4, 1, 0, 1, 5, 2])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([4., 4., 5., 5., 4., 5., 2., 5., 2., 4., 3., 3., 1., 4., 1., 1.])\n",
      "torch.Size([16])\n",
      "tensor([4, 4, 5, 5, 4, 5, 2, 5, 2, 4, 3, 3, 1, 4, 1, 1])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([4., 5., 2., 2., 5., 1., 4., 5., 4., 3., 4., 0., 4., 2., 1., 2.])\n",
      "torch.Size([16])\n",
      "tensor([4, 5, 2, 2, 5, 1, 4, 5, 4, 3, 4, 0, 4, 2, 1, 2])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([5., 3., 5., 5., 2., 3., 1., 5., 4., 0., 1., 1., 5., 4., 3., 1.])\n",
      "torch.Size([16])\n",
      "tensor([5, 3, 5, 5, 2, 3, 1, 5, 4, 0, 1, 1, 5, 4, 3, 1])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([5., 0., 4., 2., 5., 5., 5., 1., 3., 5., 2., 4., 2., 5., 2., 2.])\n",
      "torch.Size([16])\n",
      "tensor([5, 0, 4, 2, 5, 5, 5, 1, 3, 5, 2, 4, 2, 5, 2, 2])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([3., 0., 0., 4., 2., 0., 1., 0., 3., 0., 3., 0., 0., 2., 5., 0.])\n",
      "torch.Size([16])\n",
      "tensor([3, 0, 0, 4, 2, 0, 1, 0, 3, 0, 3, 0, 0, 2, 5, 0])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([4., 4., 3., 2., 1., 0., 5., 0., 1., 4., 2., 5., 0., 0., 4., 5.])\n",
      "torch.Size([16])\n",
      "tensor([4, 4, 3, 2, 1, 0, 5, 0, 1, 4, 2, 5, 0, 0, 4, 5])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([5., 4., 5., 5., 3., 0., 4., 5., 2., 1., 2., 2., 4., 0., 0., 5.])\n",
      "torch.Size([16])\n",
      "tensor([5, 4, 5, 5, 3, 0, 4, 5, 2, 1, 2, 2, 4, 0, 0, 5])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([3., 3., 1., 4., 0., 5., 0., 2., 5., 1., 5., 3., 0., 3., 2., 0.])\n",
      "torch.Size([16])\n",
      "tensor([3, 3, 1, 4, 0, 5, 0, 2, 5, 1, 5, 3, 0, 3, 2, 0])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([4., 0., 2., 5., 0., 4., 0., 5., 5., 1., 2., 5., 1., 4., 2., 2.])\n",
      "torch.Size([16])\n",
      "tensor([4, 0, 2, 5, 0, 4, 0, 5, 5, 1, 2, 5, 1, 4, 2, 2])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([3., 3., 4., 2., 3., 5., 4., 0., 5., 4., 4., 1., 5., 0., 2., 4.])\n",
      "torch.Size([16])\n",
      "tensor([3, 3, 4, 2, 3, 5, 4, 0, 5, 4, 4, 1, 5, 0, 2, 4])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([4., 3., 5., 5., 1., 4., 1., 1., 2., 5., 0., 0., 4., 5., 3., 1.])\n",
      "torch.Size([16])\n",
      "tensor([4, 3, 5, 5, 1, 4, 1, 1, 2, 5, 0, 0, 4, 5, 3, 1])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([5., 0., 3., 1., 4., 1., 1., 2., 2., 0., 0., 0., 3., 4., 0., 3.])\n",
      "torch.Size([16])\n",
      "tensor([5, 0, 3, 1, 4, 1, 1, 2, 2, 0, 0, 0, 3, 4, 0, 3])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([0., 3., 2., 5., 0., 3., 4., 3., 2., 1., 0., 5., 0., 5., 5., 5.])\n",
      "torch.Size([16])\n",
      "tensor([0, 3, 2, 5, 0, 3, 4, 3, 2, 1, 0, 5, 0, 5, 5, 5])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([1., 2., 0., 1., 1., 0., 5., 4., 3., 1., 3., 2., 4., 3., 1., 0.])\n",
      "torch.Size([16])\n",
      "tensor([1, 2, 0, 1, 1, 0, 5, 4, 3, 1, 3, 2, 4, 3, 1, 0])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([5., 3., 2., 2., 1., 2., 0., 5., 3., 4., 4., 5., 5., 3., 4., 0.])\n",
      "torch.Size([16])\n",
      "tensor([5, 3, 2, 2, 1, 2, 0, 5, 3, 4, 4, 5, 5, 3, 4, 0])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([5., 2., 2., 3., 0., 5., 2., 5., 4., 4., 4., 1., 5., 5., 3., 2.])\n",
      "torch.Size([16])\n",
      "tensor([5, 2, 2, 3, 0, 5, 2, 5, 4, 4, 4, 1, 5, 5, 3, 2])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([0., 1., 3., 1., 1., 2., 4., 3., 4., 0., 1., 0., 1., 5., 1., 3.])\n",
      "torch.Size([16])\n",
      "tensor([0, 1, 3, 1, 1, 2, 4, 3, 4, 0, 1, 0, 1, 5, 1, 3])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([5., 3., 2., 1., 0., 3., 3., 1., 5., 2., 0., 5., 5., 3., 5., 5.])\n",
      "torch.Size([16])\n",
      "tensor([5, 3, 2, 1, 0, 3, 3, 1, 5, 2, 0, 5, 5, 3, 5, 5])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([3., 3., 4., 1., 3., 2., 2., 1., 4., 4., 0., 5., 0., 4., 4., 1.])\n",
      "torch.Size([16])\n",
      "tensor([3, 3, 4, 1, 3, 2, 2, 1, 4, 4, 0, 5, 0, 4, 4, 1])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([4., 5., 4., 4., 3., 3., 5., 3., 4., 1., 5., 4., 2., 5., 5., 3.])\n",
      "torch.Size([16])\n",
      "tensor([4, 5, 4, 4, 3, 3, 5, 3, 4, 1, 5, 4, 2, 5, 5, 3])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([3., 4., 1., 2., 1., 0., 3., 5., 1., 4., 4., 0., 0., 5., 0., 4.])\n",
      "torch.Size([16])\n",
      "tensor([3, 4, 1, 2, 1, 0, 3, 5, 1, 4, 4, 0, 0, 5, 0, 4])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([1., 3., 1., 3., 0., 4., 2., 3., 1., 5., 0., 4., 3., 0., 5., 1.])\n",
      "torch.Size([16])\n",
      "tensor([1, 3, 1, 3, 0, 4, 2, 3, 1, 5, 0, 4, 3, 0, 5, 1])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([0., 0., 4., 5., 5., 4., 4., 4., 1., 5., 4., 4., 2., 5., 5., 2.])\n",
      "torch.Size([16])\n",
      "tensor([0, 0, 4, 5, 5, 4, 4, 4, 1, 5, 4, 4, 2, 5, 5, 2])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([0., 3., 1., 0., 5., 0., 1., 2., 0., 2., 1., 3., 0., 5., 5., 4.])\n",
      "torch.Size([16])\n",
      "tensor([0, 3, 1, 0, 5, 0, 1, 2, 0, 2, 1, 3, 0, 5, 5, 4])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([3., 5., 3., 3., 1., 5., 3., 3., 5., 1., 4., 0., 0., 5., 1., 4.])\n",
      "torch.Size([16])\n",
      "tensor([3, 5, 3, 3, 1, 5, 3, 3, 5, 1, 4, 0, 0, 5, 1, 4])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([3., 4., 5., 3., 0., 1., 4., 3., 2., 5., 4., 4., 1., 3., 1., 4.])\n",
      "torch.Size([16])\n",
      "tensor([3, 4, 5, 3, 0, 1, 4, 3, 2, 5, 4, 4, 1, 3, 1, 4])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([1., 2., 0., 5., 5., 2., 4., 3., 0., 2., 1., 4., 1., 3., 2., 5.])\n",
      "torch.Size([16])\n",
      "tensor([1, 2, 0, 5, 5, 2, 4, 3, 0, 2, 1, 4, 1, 3, 2, 5])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([0., 3., 3., 5., 5., 1., 0., 2., 1., 4., 3., 4., 2., 5., 4., 5.])\n",
      "torch.Size([16])\n",
      "tensor([0, 3, 3, 5, 5, 1, 0, 2, 1, 4, 3, 4, 2, 5, 4, 5])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([4., 4., 3., 3., 1., 2., 1., 2., 0., 0., 5., 5., 5., 1., 4., 5.])\n",
      "torch.Size([16])\n",
      "tensor([4, 4, 3, 3, 1, 2, 1, 2, 0, 0, 5, 5, 5, 1, 4, 5])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([2., 1., 3., 1., 5., 5., 4., 2., 1., 0., 0., 2., 4., 5., 4., 3.])\n",
      "torch.Size([16])\n",
      "tensor([2, 1, 3, 1, 5, 5, 4, 2, 1, 0, 0, 2, 4, 5, 4, 3])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([1., 5., 0., 4., 5., 1., 5., 0., 3., 3., 5., 3., 3., 2., 0., 5.])\n",
      "torch.Size([16])\n",
      "tensor([1, 5, 0, 4, 5, 1, 5, 0, 3, 3, 5, 3, 3, 2, 0, 5])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([4., 0., 2., 5., 3., 2., 0., 4., 2., 2., 0., 4., 3., 4., 3., 1.])\n",
      "torch.Size([16])\n",
      "tensor([4, 0, 2, 5, 3, 2, 0, 4, 2, 2, 0, 4, 3, 4, 3, 1])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([4., 4., 1., 1., 0., 3., 3., 5., 5., 5., 0., 5., 4., 5., 0., 2.])\n",
      "torch.Size([16])\n",
      "tensor([4, 4, 1, 1, 0, 3, 3, 5, 5, 5, 0, 5, 4, 5, 0, 2])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([4., 3., 1., 1., 1., 3., 5., 5., 0., 0., 4., 3., 5., 1., 1., 1.])\n",
      "torch.Size([16])\n",
      "tensor([4, 3, 1, 1, 1, 3, 5, 5, 0, 0, 4, 3, 5, 1, 1, 1])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([0., 4., 4., 3., 0., 4., 0., 4., 4., 3., 3., 4., 0., 1., 3., 3.])\n",
      "torch.Size([16])\n",
      "tensor([0, 4, 4, 3, 0, 4, 0, 4, 4, 3, 3, 4, 0, 1, 3, 3])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([0., 5., 2., 3., 0., 4., 1., 4., 1., 0., 0., 1., 2., 4., 1., 2.])\n",
      "torch.Size([16])\n",
      "tensor([0, 5, 2, 3, 0, 4, 1, 4, 1, 0, 0, 1, 2, 4, 1, 2])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([4., 1., 3., 2., 2., 3., 5., 1., 4., 5., 4., 4., 2., 3., 1., 1.])\n",
      "torch.Size([16])\n",
      "tensor([4, 1, 3, 2, 2, 3, 5, 1, 4, 5, 4, 4, 2, 3, 1, 1])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([2., 1., 0., 0., 1., 1., 1., 3., 1., 0., 0., 5., 3., 2., 0., 5.])\n",
      "torch.Size([16])\n",
      "tensor([2, 1, 0, 0, 1, 1, 1, 3, 1, 0, 0, 5, 3, 2, 0, 5])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([3., 0., 2., 4., 0., 3., 2., 3., 5., 1., 4., 1., 5., 5., 5., 3.])\n",
      "torch.Size([16])\n",
      "tensor([3, 0, 2, 4, 0, 3, 2, 3, 5, 1, 4, 1, 5, 5, 5, 3])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([0., 3., 3., 1., 2., 3., 5., 3., 5., 4., 1., 3., 3., 3., 3., 1.])\n",
      "torch.Size([16])\n",
      "tensor([0, 3, 3, 1, 2, 3, 5, 3, 5, 4, 1, 3, 3, 3, 3, 1])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([4., 4., 5., 5., 4., 4., 0., 1., 1., 4., 1., 2., 4., 1., 5., 0.])\n",
      "torch.Size([16])\n",
      "tensor([4, 4, 5, 5, 4, 4, 0, 1, 1, 4, 1, 2, 4, 1, 5, 0])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([3., 4., 5., 5., 2., 1., 0., 5., 1., 0., 4., 5., 3., 0., 1., 0.])\n",
      "torch.Size([16])\n",
      "tensor([3, 4, 5, 5, 2, 1, 0, 5, 1, 0, 4, 5, 3, 0, 1, 0])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([0., 2., 3., 0., 0., 3., 2., 2., 5., 1., 3., 5., 2., 4., 1., 0.])\n",
      "torch.Size([16])\n",
      "tensor([0, 2, 3, 0, 0, 3, 2, 2, 5, 1, 3, 5, 2, 4, 1, 0])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([3., 5., 1., 4., 2., 3., 2., 1., 4., 3., 1., 0., 4., 3., 5., 3.])\n",
      "torch.Size([16])\n",
      "tensor([3, 5, 1, 4, 2, 3, 2, 1, 4, 3, 1, 0, 4, 3, 5, 3])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([3., 3., 2., 1., 2., 0., 3., 3., 0., 5., 2., 3., 1., 1., 5., 2.])\n",
      "torch.Size([16])\n",
      "tensor([3, 3, 2, 1, 2, 0, 3, 3, 0, 5, 2, 3, 1, 1, 5, 2])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([2., 5., 4., 5., 0., 2., 5., 1., 3., 1., 0., 3., 0., 4., 1., 0.])\n",
      "torch.Size([16])\n",
      "tensor([2, 5, 4, 5, 0, 2, 5, 1, 3, 1, 0, 3, 0, 4, 1, 0])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([5., 0., 1., 2., 1., 4., 2., 5., 2., 2., 0., 2., 2., 4., 3., 2.])\n",
      "torch.Size([16])\n",
      "tensor([5, 0, 1, 2, 1, 4, 2, 5, 2, 2, 0, 2, 2, 4, 3, 2])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([3., 5., 2., 4., 0., 3., 2., 2., 3., 3., 2., 5., 0., 1., 2., 1.])\n",
      "torch.Size([16])\n",
      "tensor([3, 5, 2, 4, 0, 3, 2, 2, 3, 3, 2, 5, 0, 1, 2, 1])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([2., 4., 3., 3., 3., 0., 0., 1., 3., 1., 0., 5., 2., 5., 2., 1.])\n",
      "torch.Size([16])\n",
      "tensor([2, 4, 3, 3, 3, 0, 0, 1, 3, 1, 0, 5, 2, 5, 2, 1])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([0., 4., 3., 2., 5., 5., 0., 1., 4., 5., 3., 2., 1., 2., 5., 2.])\n",
      "torch.Size([16])\n",
      "tensor([0, 4, 3, 2, 5, 5, 0, 1, 4, 5, 3, 2, 1, 2, 5, 2])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([3., 5., 0., 5., 1., 2., 0., 2., 5., 4., 4., 3., 2., 2., 2., 4.])\n",
      "torch.Size([16])\n",
      "tensor([3, 5, 0, 5, 1, 2, 0, 2, 5, 4, 4, 3, 2, 2, 2, 4])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([4., 0., 4., 2., 3., 4., 5., 0., 2., 5., 1., 1., 5., 5., 0., 4.])\n",
      "torch.Size([16])\n",
      "tensor([4, 0, 4, 2, 3, 4, 5, 0, 2, 5, 1, 1, 5, 5, 0, 4])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([1., 2., 2., 0., 4., 3., 5., 2., 2., 2., 4., 0., 5., 5., 4., 5.])\n",
      "torch.Size([16])\n",
      "tensor([1, 2, 2, 0, 4, 3, 5, 2, 2, 2, 4, 0, 5, 5, 4, 5])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([5., 0., 5., 5., 3., 5., 1., 3., 2., 0., 1., 2., 2., 0., 2., 3.])\n",
      "torch.Size([16])\n",
      "tensor([5, 0, 5, 5, 3, 5, 1, 3, 2, 0, 1, 2, 2, 0, 2, 3])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([2., 0., 3., 0., 4., 1., 0., 1., 2., 3., 1., 4., 1., 3., 1., 4.])\n",
      "torch.Size([16])\n",
      "tensor([2, 0, 3, 0, 4, 1, 0, 1, 2, 3, 1, 4, 1, 3, 1, 4])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([5., 0., 3., 1., 1., 4., 5., 5., 2., 3., 2., 0., 2., 1., 4., 3.])\n",
      "torch.Size([16])\n",
      "tensor([5, 0, 3, 1, 1, 4, 5, 5, 2, 3, 2, 0, 2, 1, 4, 3])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([1., 1., 4., 2., 0., 4., 5., 4., 1., 5., 5., 1., 1., 3., 3., 1.])\n",
      "torch.Size([16])\n",
      "tensor([1, 1, 4, 2, 0, 4, 5, 4, 1, 5, 5, 1, 1, 3, 3, 1])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([5., 4., 5., 5., 5., 3., 5., 0., 4., 0., 0., 3., 4., 4., 4., 0.])\n",
      "torch.Size([16])\n",
      "tensor([5, 4, 5, 5, 5, 3, 5, 0, 4, 0, 0, 3, 4, 4, 4, 0])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([3., 2., 4., 0., 1., 1., 0., 4., 5., 4., 2., 5., 3., 0., 5., 5.])\n",
      "torch.Size([16])\n",
      "tensor([3, 2, 4, 0, 1, 1, 0, 4, 5, 4, 2, 5, 3, 0, 5, 5])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([2., 3., 2., 2., 5., 5., 0., 0., 4., 2., 5., 1., 3., 5., 0., 0.])\n",
      "torch.Size([16])\n",
      "tensor([2, 3, 2, 2, 5, 5, 0, 0, 4, 2, 5, 1, 3, 5, 0, 0])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([4., 1., 0., 2., 0., 1., 3., 1., 2., 2., 2., 4., 5., 5., 3., 2.])\n",
      "torch.Size([16])\n",
      "tensor([4, 1, 0, 2, 0, 1, 3, 1, 2, 2, 2, 4, 5, 5, 3, 2])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([2., 1., 0., 4., 1., 0., 1., 3., 2., 2., 4., 3., 0., 3., 5., 3.])\n",
      "torch.Size([16])\n",
      "tensor([2, 1, 0, 4, 1, 0, 1, 3, 2, 2, 4, 3, 0, 3, 5, 3])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([4., 4., 2., 5., 3., 0., 1., 4., 0., 5., 1., 0., 1., 1., 0., 0.])\n",
      "torch.Size([16])\n",
      "tensor([4, 4, 2, 5, 3, 0, 1, 4, 0, 5, 1, 0, 1, 1, 0, 0])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([3., 1., 3., 4., 1., 0., 5., 3., 3., 2., 2., 3., 0., 5., 0., 2.])\n",
      "torch.Size([16])\n",
      "tensor([3, 1, 3, 4, 1, 0, 5, 3, 3, 2, 2, 3, 0, 5, 0, 2])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([2., 5., 5., 0., 2., 0., 1., 1., 0., 5., 0., 3., 2., 5., 3., 0.])\n",
      "torch.Size([16])\n",
      "tensor([2, 5, 5, 0, 2, 0, 1, 1, 0, 5, 0, 3, 2, 5, 3, 0])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([3., 5., 3., 2., 3., 3., 4., 0., 1., 0., 4., 5., 1., 3., 2., 4.])\n",
      "torch.Size([16])\n",
      "tensor([3, 5, 3, 2, 3, 3, 4, 0, 1, 0, 4, 5, 1, 3, 2, 4])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([2., 5., 5., 3., 0., 5., 2., 4., 1., 2., 2., 0., 4., 4., 5., 2.])\n",
      "torch.Size([16])\n",
      "tensor([2, 5, 5, 3, 0, 5, 2, 4, 1, 2, 2, 0, 4, 4, 5, 2])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([2., 2., 4., 5., 3., 3., 4., 0., 3., 0., 0., 4., 1., 4., 0., 2.])\n",
      "torch.Size([16])\n",
      "tensor([2, 2, 4, 5, 3, 3, 4, 0, 3, 0, 0, 4, 1, 4, 0, 2])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([0., 2., 5., 1., 5., 3., 4., 2., 5., 0., 0., 0., 5., 1., 0., 4.])\n",
      "torch.Size([16])\n",
      "tensor([0, 2, 5, 1, 5, 3, 4, 2, 5, 0, 0, 0, 5, 1, 0, 4])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([3., 2., 0., 4., 3., 4., 4., 1., 2., 0., 2., 2., 5., 5., 4., 1.])\n",
      "torch.Size([16])\n",
      "tensor([3, 2, 0, 4, 3, 4, 4, 1, 2, 0, 2, 2, 5, 5, 4, 1])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([4., 1., 0., 2., 5., 4., 2., 2., 0., 5., 3., 3., 4., 0., 1., 4.])\n",
      "torch.Size([16])\n",
      "tensor([4, 1, 0, 2, 5, 4, 2, 2, 0, 5, 3, 3, 4, 0, 1, 4])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([3., 5., 3., 4., 4., 5., 2., 3., 0., 3., 1., 2., 4., 5., 1., 0.])\n",
      "torch.Size([16])\n",
      "tensor([3, 5, 3, 4, 4, 5, 2, 3, 0, 3, 1, 2, 4, 5, 1, 0])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([2., 5., 2., 3., 4., 1., 3., 0., 1., 5., 3., 5., 1., 3., 4., 3.])\n",
      "torch.Size([16])\n",
      "tensor([2, 5, 2, 3, 4, 1, 3, 0, 1, 5, 3, 5, 1, 3, 4, 3])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([1., 2., 4., 4., 3., 5., 5., 3., 4., 3., 0., 4., 4., 2., 1., 5.])\n",
      "torch.Size([16])\n",
      "tensor([1, 2, 4, 4, 3, 5, 5, 3, 4, 3, 0, 4, 4, 2, 1, 5])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([5., 1., 5., 4., 4., 5., 5., 0., 2., 5., 2., 5., 3., 0., 3., 3.])\n",
      "torch.Size([16])\n",
      "tensor([5, 1, 5, 4, 4, 5, 5, 0, 2, 5, 2, 5, 3, 0, 3, 3])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([4., 4., 4., 5., 3., 2., 2., 1., 0., 5., 0., 2., 5., 5., 4., 0.])\n",
      "torch.Size([16])\n",
      "tensor([4, 4, 4, 5, 3, 2, 2, 1, 0, 5, 0, 2, 5, 5, 4, 0])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([0., 3., 0., 4., 4., 4., 3., 3., 0., 5., 0., 4., 5., 0., 1., 1.])\n",
      "torch.Size([16])\n",
      "tensor([0, 3, 0, 4, 4, 4, 3, 3, 0, 5, 0, 4, 5, 0, 1, 1])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([4., 3., 5., 4., 4., 4., 2., 3., 2., 4., 0., 3., 0., 4., 2., 1.])\n",
      "torch.Size([16])\n",
      "tensor([4, 3, 5, 4, 4, 4, 2, 3, 2, 4, 0, 3, 0, 4, 2, 1])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([4., 5., 5., 4., 1., 2., 5., 0., 1., 5., 5., 3., 5., 1., 3., 4.])\n",
      "torch.Size([16])\n",
      "tensor([4, 5, 5, 4, 1, 2, 5, 0, 1, 5, 5, 3, 5, 1, 3, 4])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([5., 4., 3., 5., 1., 3., 0., 3., 0., 2., 3., 4., 2., 4., 2., 1.])\n",
      "torch.Size([16])\n",
      "tensor([5, 4, 3, 5, 1, 3, 0, 3, 0, 2, 3, 4, 2, 4, 2, 1])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([3., 3., 3., 0., 2., 3., 4., 3., 5., 1., 4., 4., 0., 5., 4., 2.])\n",
      "torch.Size([16])\n",
      "tensor([3, 3, 3, 0, 2, 3, 4, 3, 5, 1, 4, 4, 0, 5, 4, 2])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([0., 2., 4., 0., 1., 5., 1., 3., 0., 5., 3., 1., 1., 1., 3., 5.])\n",
      "torch.Size([16])\n",
      "tensor([0, 2, 4, 0, 1, 5, 1, 3, 0, 5, 3, 1, 1, 1, 3, 5])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([4., 1., 2., 0., 3., 0., 4., 2., 2., 4., 4., 3., 3., 0., 3., 4.])\n",
      "torch.Size([16])\n",
      "tensor([4, 1, 2, 0, 3, 0, 4, 2, 2, 4, 4, 3, 3, 0, 3, 4])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([4., 4., 0., 0., 3., 1., 4., 2., 5., 4., 2., 1., 3., 5., 4., 2.])\n",
      "torch.Size([16])\n",
      "tensor([4, 4, 0, 0, 3, 1, 4, 2, 5, 4, 2, 1, 3, 5, 4, 2])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([3., 5., 5., 4., 5., 0., 0., 4., 0., 5., 3., 3., 0., 5., 1., 4.])\n",
      "torch.Size([16])\n",
      "tensor([3, 5, 5, 4, 5, 0, 0, 4, 0, 5, 3, 3, 0, 5, 1, 4])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([3., 4., 2., 1., 1., 2., 4., 4., 5., 5., 3., 4., 0., 1., 3., 1.])\n",
      "torch.Size([16])\n",
      "tensor([3, 4, 2, 1, 1, 2, 4, 4, 5, 5, 3, 4, 0, 1, 3, 1])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([5., 0., 1., 4., 4., 1., 2., 2., 2., 1., 5., 1., 3., 0., 4., 2.])\n",
      "torch.Size([16])\n",
      "tensor([5, 0, 1, 4, 4, 1, 2, 2, 2, 1, 5, 1, 3, 0, 4, 2])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([2., 5., 4., 5., 1., 3., 0., 1., 2., 5., 3., 0., 4., 3., 5., 5.])\n",
      "torch.Size([16])\n",
      "tensor([2, 5, 4, 5, 1, 3, 0, 1, 2, 5, 3, 0, 4, 3, 5, 5])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([3., 3., 5., 4., 4., 5., 0., 1., 2., 1., 2., 4., 1., 1., 4., 5.])\n",
      "torch.Size([16])\n",
      "tensor([3, 3, 5, 4, 4, 5, 0, 1, 2, 1, 2, 4, 1, 1, 4, 5])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([1., 3., 3., 0., 3., 0., 1., 5., 5., 4., 3., 4., 1., 2., 5., 1.])\n",
      "torch.Size([16])\n",
      "tensor([1, 3, 3, 0, 3, 0, 1, 5, 5, 4, 3, 4, 1, 2, 5, 1])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([3., 3., 4., 5., 0., 0., 1., 5., 3., 5., 3., 3., 0., 0., 3., 3.])\n",
      "torch.Size([16])\n",
      "tensor([3, 3, 4, 5, 0, 0, 1, 5, 3, 5, 3, 3, 0, 0, 3, 3])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([4., 3., 1., 2., 2., 0., 4., 5., 3., 4., 1., 5., 5., 0., 5., 3.])\n",
      "torch.Size([16])\n",
      "tensor([4, 3, 1, 2, 2, 0, 4, 5, 3, 4, 1, 5, 5, 0, 5, 3])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([1., 1., 2., 4., 1., 2., 5., 4., 3., 4., 4., 5., 3., 3., 5., 1.])\n",
      "torch.Size([16])\n",
      "tensor([1, 1, 2, 4, 1, 2, 5, 4, 3, 4, 4, 5, 3, 3, 5, 1])\n",
      "torch.Size([16, 128, 9])\n",
      "torch.Size([16, 1])\n",
      "tensor([5., 0., 3., 5., 1., 4., 3., 4., 1., 1., 5., 0., 2., 2., 1., 0.])\n",
      "torch.Size([16])\n",
      "tensor([5, 0, 3, 5, 1, 4, 3, 4, 1, 1, 5, 0, 2, 2, 1, 0])\n",
      "torch.Size([3, 128, 9])\n",
      "torch.Size([3, 1])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "torch.Size([3])\n",
      "tensor([2, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "y = torch.zeros((len(t), batch_size))\n",
    "for j,sam in enumerate(t):\n",
    "    f,lab = sam\n",
    "    print(f.shape)\n",
    "    print(lab.shape)\n",
    "    lab = lab.view(lab.size(0))\n",
    "    lab = lab.type(torch.LongTensor)\n",
    "    if(lab.size(0)==16):\n",
    "        y[j] = lab\n",
    "    print(y[j])\n",
    "    #l,_ = torch.max(lab,1)\n",
    "    print(lab.shape)\n",
    "    print(lab)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-notification",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
